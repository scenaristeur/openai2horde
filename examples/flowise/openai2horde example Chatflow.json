{
  "nodes": [
    {
      "width": 300,
      "height": 378,
      "id": "bufferMemory_0",
      "position": {
        "x": 753.4300788823234,
        "y": 479.5336426526603
      },
      "type": "customNode",
      "data": {
        "id": "bufferMemory_0",
        "label": "Buffer Memory",
        "version": 1,
        "name": "bufferMemory",
        "type": "BufferMemory",
        "baseClasses": [
          "BufferMemory",
          "BaseChatMemory",
          "BaseMemory"
        ],
        "category": "Memory",
        "description": "Remembers previous conversational back and forths directly",
        "inputParams": [
          {
            "label": "Memory Key",
            "name": "memoryKey",
            "type": "string",
            "default": "chat_history",
            "id": "bufferMemory_0-input-memoryKey-string"
          },
          {
            "label": "Input Key",
            "name": "inputKey",
            "type": "string",
            "default": "input",
            "id": "bufferMemory_0-input-inputKey-string"
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "memoryKey": "chat_history",
          "inputKey": "input"
        },
        "outputAnchors": [
          {
            "id": "bufferMemory_0-output-bufferMemory-BufferMemory|BaseChatMemory|BaseMemory",
            "name": "bufferMemory",
            "label": "BufferMemory",
            "type": "BufferMemory | BaseChatMemory | BaseMemory"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "selected": false,
      "positionAbsolute": {
        "x": 753.4300788823234,
        "y": 479.5336426526603
      },
      "dragging": false
    },
    {
      "width": 300,
      "height": 385,
      "id": "conversationChain_0",
      "position": {
        "x": 1174.6496397666272,
        "y": 311.1052536740497
      },
      "type": "customNode",
      "data": {
        "id": "conversationChain_0",
        "label": "Conversation Chain",
        "version": 1,
        "name": "conversationChain",
        "type": "ConversationChain",
        "baseClasses": [
          "ConversationChain",
          "LLMChain",
          "BaseChain"
        ],
        "category": "Chains",
        "description": "Chat models specific conversational chain with memory",
        "inputParams": [
          {
            "label": "System Message",
            "name": "systemMessagePrompt",
            "type": "string",
            "rows": 4,
            "additionalParams": true,
            "optional": true,
            "placeholder": "You are a helpful assistant that write codes",
            "id": "conversationChain_0-input-systemMessagePrompt-string"
          }
        ],
        "inputAnchors": [
          {
            "label": "Language Model",
            "name": "model",
            "type": "BaseChatModel",
            "id": "conversationChain_0-input-model-BaseChatModel"
          },
          {
            "label": "Memory",
            "name": "memory",
            "type": "BaseMemory",
            "id": "conversationChain_0-input-memory-BaseMemory"
          },
          {
            "label": "Document",
            "name": "document",
            "type": "Document",
            "description": "Include whole document into the context window",
            "optional": true,
            "list": true,
            "id": "conversationChain_0-input-document-Document"
          }
        ],
        "inputs": {
          "model": "{{chatLocalAI_0.data.instance}}",
          "memory": "{{bufferMemory_0.data.instance}}",
          "document": "",
          "systemMessagePrompt": "You are a helpful assistant. You only give answer text, with no explanation, no JSON."
        },
        "outputAnchors": [
          {
            "id": "conversationChain_0-output-conversationChain-ConversationChain|LLMChain|BaseChain",
            "name": "conversationChain",
            "label": "ConversationChain",
            "type": "ConversationChain | LLMChain | BaseChain"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "selected": false,
      "positionAbsolute": {
        "x": 1174.6496397666272,
        "y": 311.1052536740497
      },
      "dragging": false
    },
    {
      "width": 300,
      "height": 580,
      "id": "chatLocalAI_0",
      "position": {
        "x": 750.8424769505194,
        "y": -126.77883180495417
      },
      "type": "customNode",
      "data": {
        "id": "chatLocalAI_0",
        "label": "ChatLocalAI",
        "version": 2,
        "name": "chatLocalAI",
        "type": "ChatLocalAI",
        "baseClasses": [
          "ChatLocalAI",
          "BaseChatModel",
          "LLM",
          "BaseLLM",
          "BaseLanguageModel",
          "Runnable"
        ],
        "category": "Chat Models",
        "description": "Use local LLMs like llama.cpp, gpt4all using LocalAI",
        "inputParams": [
          {
            "label": "Base Path",
            "name": "basePath",
            "type": "string",
            "placeholder": "http://localhost:8080/v1",
            "id": "chatLocalAI_0-input-basePath-string"
          },
          {
            "label": "Model Name",
            "name": "modelName",
            "type": "string",
            "placeholder": "gpt4all-lora-quantized.bin",
            "id": "chatLocalAI_0-input-modelName-string"
          },
          {
            "label": "Temperature",
            "name": "temperature",
            "type": "number",
            "step": 0.1,
            "default": 0.9,
            "optional": true,
            "id": "chatLocalAI_0-input-temperature-number"
          },
          {
            "label": "Max Tokens",
            "name": "maxTokens",
            "type": "number",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "chatLocalAI_0-input-maxTokens-number"
          },
          {
            "label": "Top Probability",
            "name": "topP",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "chatLocalAI_0-input-topP-number"
          },
          {
            "label": "Timeout",
            "name": "timeout",
            "type": "number",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "chatLocalAI_0-input-timeout-number"
          }
        ],
        "inputAnchors": [
          {
            "label": "Cache",
            "name": "cache",
            "type": "BaseCache",
            "optional": true,
            "id": "chatLocalAI_0-input-cache-BaseCache"
          }
        ],
        "inputs": {
          "cache": "",
          "basePath": "http://localhost:5678/v1",
          "modelName": "no model specified",
          "temperature": "0",
          "maxTokens": "",
          "topP": "",
          "timeout": ""
        },
        "outputAnchors": [
          {
            "id": "chatLocalAI_0-output-chatLocalAI-ChatLocalAI|BaseChatModel|LLM|BaseLLM|BaseLanguageModel|Runnable",
            "name": "chatLocalAI",
            "label": "ChatLocalAI",
            "type": "ChatLocalAI | BaseChatModel | LLM | BaseLLM | BaseLanguageModel | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "selected": false,
      "positionAbsolute": {
        "x": 750.8424769505194,
        "y": -126.77883180495417
      },
      "dragging": false
    }
  ],
  "edges": [
    {
      "source": "bufferMemory_0",
      "sourceHandle": "bufferMemory_0-output-bufferMemory-BufferMemory|BaseChatMemory|BaseMemory",
      "target": "conversationChain_0",
      "targetHandle": "conversationChain_0-input-memory-BaseMemory",
      "type": "buttonedge",
      "id": "bufferMemory_0-bufferMemory_0-output-bufferMemory-BufferMemory|BaseChatMemory|BaseMemory-conversationChain_0-conversationChain_0-input-memory-BaseMemory",
      "data": {
        "label": ""
      }
    },
    {
      "source": "chatLocalAI_0",
      "sourceHandle": "chatLocalAI_0-output-chatLocalAI-ChatLocalAI|BaseChatModel|LLM|BaseLLM|BaseLanguageModel|Runnable",
      "target": "conversationChain_0",
      "targetHandle": "conversationChain_0-input-model-BaseChatModel",
      "type": "buttonedge",
      "id": "chatLocalAI_0-chatLocalAI_0-output-chatLocalAI-ChatLocalAI|BaseChatModel|LLM|BaseLLM|BaseLanguageModel|Runnable-conversationChain_0-conversationChain_0-input-model-BaseChatModel",
      "data": {
        "label": ""
      }
    }
  ]
}